{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "746dbe3a",
   "metadata": {},
   "source": [
    "# Read and Analyze AlphaFold Server Outputs\n",
    "\n",
    "1. Run AlphaFold Server\n",
    "2. Downlaod ZIP files from Google Drive\n",
    "3. Place ZIP files in the defined folder\n",
    "4. Run Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0ac741",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c227ca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q numpy pandas matplotlib py3Dmol openpyxl Bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8be42b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import json\n",
    "import py3Dmol\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0296312",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1e8060",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    AF_DIR = \"AlphaFold\"\n",
    "    CANDIDATE_NUM = \"1\"\n",
    "\n",
    "config = Config()\n",
    "\n",
    "dir = Path(config.AF_DIR)\n",
    "if not dir.exists():\n",
    "    print(f\"Creating directory: {dir}\")\n",
    "    dir.mkdir()\n",
    "\n",
    "print(f\"Searching for ColabFold .zip outputs in: {dir}\")\n",
    "\n",
    "# Find all zip files in the directory\n",
    "zip_files = list(dir.glob(\"*.zip\"))\n",
    "\n",
    "if not zip_files:\n",
    "    print(\"\\nERROR: No .zip files found in the validation directory.\")\n",
    "    print(\"Please make sure to place your ColabFold outputs there before running this cell.\")\n",
    "else:\n",
    "    print(f\"Found {len(zip_files)} candidate zip files to analyze.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302576b8",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7c1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from Bio.PDB import MMCIFParser, PDBIO\n",
    "from IPython.display import Image\n",
    "LOOP_START_RESIDUE = 62\n",
    "LOOP_END_RESIDUE = 69\n",
    "CHAIN_SPLIT_POINT = 188  # Adjust based on your specific protein complex\n",
    "\n",
    "results_list = []\n",
    "\n",
    "# --- LOOP THROUGH EACH ZIP FILE AND ANALYZE ---\n",
    "for zip_file_path in sorted(zip_files):\n",
    "    candidate_name = zip_file_path.stem\n",
    "    display(HTML(f\"<hr><h2>Analyzing Candidate: {candidate_name} (Model {config.CANDIDATE_NUM})</h2>\"))\n",
    "\n",
    "    temp_split = candidate_name.split('_')\n",
    "\n",
    "    if len(temp_split) >= 4:\n",
    "        ligand_name = temp_split[1]\n",
    "        target_name = temp_split[3]\n",
    "        variant_name = temp_split[4]\n",
    "    else:\n",
    "        print(\"WARNING: Candidate names do not match the expected format {ligand}_variant_{target}_{variant}. Cannot create comparison matrices.\")\n",
    "        ligand_name = \"Chain A\"\n",
    "        target_name = \"Chain B\"\n",
    "        variant_name = \"Unknown\"\n",
    "        \n",
    "    # Unzip the contents into a subdirectory\n",
    "    unzip_dir = dir / candidate_name\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(unzip_dir)\n",
    "    \n",
    "    # Find the files for the top-ranked model (rank 1)\n",
    "    try:\n",
    "        scores_file = next(unzip_dir.glob(f\"*_summary_confidences_{config.CANDIDATE_NUM}.json\"))\n",
    "        full_data_file = next(unzip_dir.glob(f\"*_full_data_{config.CANDIDATE_NUM}.json\"))\n",
    "        structure_file = next(unzip_dir.glob(f\"*_model_{config.CANDIDATE_NUM}.cif\"))\n",
    "    except StopIteration:\n",
    "        print(f\"WARNING: Could not find all required output files for rank {config.CANDIDATE_NUM} in {candidate_name}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # --- EXTRACT AND DISPLAY KEY SCORES ---\n",
    "    with open(scores_file, 'r') as f:\n",
    "        scores_data = json.load(f)\n",
    "\n",
    "    ipTM_score = scores_data.get(\"iptm\")\n",
    "\n",
    "    with open(full_data_file, 'r') as f:\n",
    "        pae_data = json.load(f)\n",
    "\n",
    "    plddt_array = pae_data.get(\"atom_plddts\")\n",
    "    mean_plddt = np.mean(plddt_array) if plddt_array else 0\n",
    "    \n",
    "    # --- NEW: TARGETED pLDDT ANALYSIS FOR THE MODIFIED LOOP (CIF-based) ---\n",
    "    print(f\"\\n--- Targeted pLDDT Analysis (Loop {LOOP_START_RESIDUE}-{LOOP_END_RESIDUE}) ---\")\n",
    "\n",
    "    # Define the chain your loop is on\n",
    "    LOOP_CHAIN_ID = 'A' \n",
    "    loop_plddt_values = []\n",
    "\n",
    "    try:\n",
    "        # 1. Parse the mmCIF file (you already do this later, but we move it up)\n",
    "        parser = MMCIFParser()\n",
    "        structure = parser.get_structure(candidate_name, str(structure_file))\n",
    "        \n",
    "        # Get the specific model (usually model 1, index 0)\n",
    "        model = structure[0]\n",
    "        \n",
    "        # Get the specific chain\n",
    "        chain = model[LOOP_CHAIN_ID]\n",
    "\n",
    "        # 2. Loop through the residues in the target range\n",
    "        for res_num in range(LOOP_START_RESIDUE, LOOP_END_RESIDUE + 1):\n",
    "            # Bio.PDB requires a full residue ID: (' ', res_num, ' ') for standard residues\n",
    "            residue_id = (' ', res_num, ' ')\n",
    "            \n",
    "            try:\n",
    "                residue = chain[residue_id]\n",
    "                \n",
    "                # 3. Collect the pLDDT (stored in the B-factor column) for all atoms\n",
    "                for atom in residue:\n",
    "                    # The B-factor value is the pLDDT score\n",
    "                    loop_plddt_values.append(atom.get_bfactor())\n",
    "                    \n",
    "            except KeyError:\n",
    "                # Handle cases where a residue might be missing (e.g., if it's truncated)\n",
    "                print(f\"Warning: Residue {LOOP_CHAIN_ID}:{res_num} not found in structure.\")\n",
    "                continue\n",
    "\n",
    "        # 4. Calculate the mean pLDDT for the loop\n",
    "        if loop_plddt_values:\n",
    "            loop_mean_plddt = np.mean(loop_plddt_values)\n",
    "        else:\n",
    "            loop_mean_plddt = 0.0\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR during CIF parsing for loop pLDDT: {e}\")\n",
    "        loop_mean_plddt = 0.0\n",
    "\n",
    "    if loop_mean_plddt > 0:\n",
    "        print(f\"Loop ({LOOP_CHAIN_ID}:{LOOP_START_RESIDUE}-{LOOP_END_RESIDUE}) Mean pLDDT: {loop_mean_plddt:.2f} (Targeted loop confidence)\")\n",
    "    else:\n",
    "        print(\"Loop pLDDT calculation failed or loop was not found.\")\n",
    "\n",
    "    results_list.append({\n",
    "        \"Candidate\": candidate_name,\n",
    "        \"ipTM\": ipTM_score,\n",
    "        \"Mean pLDDT\": mean_plddt,\n",
    "        \"Loop pLDDT\": loop_mean_plddt # Add the new score\n",
    "    })\n",
    "\n",
    "    print(\"\\n--- Confidence Scores ---\")\n",
    "    if ipTM_score is not None:\n",
    "        print(f\"Interface pTM (ipTM): {ipTM_score:.4f}\")\n",
    "        if ipTM_score > 0.85:\n",
    "            print(\"Interpretation: High confidence binding prediction.\")\n",
    "        else:\n",
    "            print(\"Interpretation: Low confidence binding prediction.\")\n",
    "    \n",
    "    if mean_plddt > 0:\n",
    "            print(f\"Mean pLDDT: {mean_plddt:.2f} (Overall structure confidence)\")\n",
    "    \n",
    "    # --- PLOT THE PAE MATRIX FROM RAW JSON DATA ---\n",
    "    pae_matrix = pae_data.get('pae')\n",
    "    if pae_matrix:\n",
    "        print(\"\\n--- Predicted Aligned Error (PAE) Plot ---\")\n",
    "        pae_matrix_np = np.array(pae_matrix)\n",
    "        total_len = len(pae_matrix_np)\n",
    "        \n",
    "        WINDOW_SIZE = 10 \n",
    "        PAE_START_A = max(0, LOOP_START_RESIDUE - 1 - WINDOW_SIZE)\n",
    "        PAE_END_A = min(CHAIN_SPLIT_POINT, LOOP_END_RESIDUE + WINDOW_SIZE)\n",
    "        \n",
    "        # Define the indices for Chain B region to display (full chain B for interface analysis)\n",
    "        PAE_START_B = CHAIN_SPLIT_POINT\n",
    "        PAE_END_B = total_len\n",
    "        \n",
    "        # The region of interest for PAE is Chain A vs Chain B (interaction)\n",
    "        # This corresponds to the top-right and bottom-left quadrants of the full matrix.\n",
    "        \n",
    "        # Full PAE Plot \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(pae_matrix_np, cmap='Greens_r', vmin=0, vmax=30)\n",
    "        \n",
    "        # --- ADD DIVIDING LINES ---\n",
    "        # Vertical line at the chain boundary\n",
    "        plt.axvline(x=CHAIN_SPLIT_POINT - 0.5, color='black', linestyle='--', linewidth=2)\n",
    "        # Horizontal line at the chain boundary\n",
    "        plt.axhline(y=CHAIN_SPLIT_POINT - 0.5, color='black', linestyle='--', linewidth=2)\n",
    "        # ---------------------------\n",
    "        \n",
    "        plt.colorbar(label=\"Expected Position Error (Å)\")\n",
    "        plt.title(f\"PAE Plot for {candidate_name} (Model {config.CANDIDATE_NUM})\")\n",
    "        \n",
    "        # Add Chain labels if desired\n",
    "        mid_A = CHAIN_SPLIT_POINT / 2\n",
    "        mid_B = (CHAIN_SPLIT_POINT + total_len) / 2\n",
    "        \n",
    "        plt.text(mid_A, total_len * 1.03, 'Chain A', ha='center', va='bottom', transform=plt.gca().transAxes, fontsize=10)\n",
    "        plt.text(mid_B, total_len * 1.03, 'Chain B', ha='center', va='bottom', transform=plt.gca().transAxes, fontsize=10)\n",
    "        plt.xlabel(\"Scored Residue\")\n",
    "        plt.ylabel(\"Aligned Residue\")\n",
    "        pae_output_path = dir / f\"PAE_{candidate_name}_model_{config.CANDIDATE_NUM}.png\"\n",
    "        plt.savefig(pae_output_path)\n",
    "        plt.close()\n",
    "\n",
    "        display(Image(filename=pae_output_path))\n",
    "\n",
    "        # Focused PAE\n",
    "        focused_pae = pae_matrix_np[PAE_START_A : PAE_END_A, PAE_START_B : PAE_END_B]\n",
    "\n",
    "        if focused_pae.size > 0:\n",
    "            pae_matrix_loop_only = pae_matrix_np[LOOP_START_RESIDUE : LOOP_END_RESIDUE, PAE_START_B : PAE_END_B] \n",
    "            mean_interface_pae_loop = np.mean(pae_matrix_loop_only)\n",
    "            print(f\"Mean Interface PAE (Loop vs {target_name}): {mean_interface_pae_loop:.2f} Å\")\n",
    "\n",
    "            plt.figure(figsize=(14, 6))\n",
    "            plt.imshow(focused_pae, cmap='bwr', vmin=0, vmax=20, aspect='auto') # Use a different cmap for contrast\n",
    "            \n",
    "            # Highlight the loop itself on the Y-axis\n",
    "            y_loop_start = LOOP_START_RESIDUE - 1 - PAE_START_A\n",
    "            y_loop_end = LOOP_END_RESIDUE - PAE_START_A\n",
    "            \n",
    "            plt.axhline(y=y_loop_start, color='green', linestyle='-', linewidth=1.5, label='Loop Start/End')\n",
    "            plt.axhline(y=y_loop_end, color='green', linestyle='-', linewidth=1.5)\n",
    "            \n",
    "            plt.colorbar(label=\"Expected Position Error (Å)\")\n",
    "            plt.title(f\"Focused PAE: {ligand_name} Loop ({LOOP_START_RESIDUE}-{LOOP_END_RESIDUE}) vs {target_name} (Model {config.CANDIDATE_NUM})\")\n",
    "            \n",
    "            # Adjust ticks to show original residue numbers\n",
    "            y_ticks = np.arange(0, focused_pae.shape[0], step=5)\n",
    "            y_labels = [str(int(PAE_START_A + t + 1)) for t in y_ticks]\n",
    "            plt.yticks(y_ticks, y_labels)\n",
    "            \n",
    "            x_ticks = np.arange(0, focused_pae.shape[1], step=100)\n",
    "            x_labels = [str(int(PAE_START_B + t + 1)) for t in x_ticks]\n",
    "            plt.xticks(x_ticks, x_labels)\n",
    "\n",
    "            plt.xlabel(f\"{target_name} Residue\")\n",
    "            plt.ylabel(f\"{ligand_name} Residue\")\n",
    "\n",
    "            focused_pae_output_path = dir / f\"PAE_focused_{candidate_name}_model_{config.CANDIDATE_NUM}.png\"\n",
    "            plt.savefig(focused_pae_output_path)\n",
    "            plt.close()\n",
    "\n",
    "            display(Image(filename=focused_pae_output_path))\n",
    "        else:\n",
    "            mean_interface_pae_loop = 0.0 \n",
    "            print(\"Warning: Interface PAE matrix slice was empty.\")\n",
    "\n",
    "        # Add to your results_list\n",
    "        results_list[-1][\"Interface PAE (Loop)\"] = mean_interface_pae_loop\n",
    "\n",
    "    print(f\"\\n--- Saving Structure to PDB Format ---\")\n",
    "\n",
    "    # Convert mmCIF to PDB\n",
    "    pdb_output_path = dir / f\"PDB_{candidate_name}_model_{config.CANDIDATE_NUM}.pdb\"\n",
    "    \n",
    "    try:\n",
    "        # 1. Parse the mmCIF file\n",
    "        parser = MMCIFParser()\n",
    "        structure = parser.get_structure(candidate_name, str(structure_file))\n",
    "        \n",
    "        # 2. Initialize the PDB writer\n",
    "        io = PDBIO()\n",
    "        io.set_structure(structure)\n",
    "        \n",
    "        # 3. Write the structure to the new PDB file\n",
    "        io.save(str(pdb_output_path))\n",
    "        print(f\"Successfully saved PDB file to: {pdb_output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to convert CIF to PDB for {candidate_name}. Error: {e}\")\n",
    "    \n",
    "    # --- VISUALIZE THE 3D STRUCTURE ---\n",
    "    print(\"\\n--- Predicted 3D Structure (Colored by pLDDT) ---\")\n",
    "    with open(structure_file, 'r') as f:\n",
    "        structure_data = f.read()\n",
    "\n",
    "    view = py3Dmol.view(width=800, height=600)\n",
    "    view.addModel(structure_data, \"mmcif\")\n",
    "    view.setStyle({'chain': 'A'}, {'cartoon': {'colorscheme': {\n",
    "        'prop': 'b', 'gradient': 'roygb', 'min': 40, 'max': 100,\n",
    "    }}})\n",
    "    view.setStyle({'chain': 'B'}, {'sphere': {}})\n",
    "    view.zoomTo()\n",
    "    view.show()\n",
    "\n",
    "    shutil.rmtree(unzip_dir)  # Clean up the unzipped directory\n",
    "    print(f\"Cleaned up temporary files for candidate: {candidate_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed398f9",
   "metadata": {},
   "source": [
    "### Compare across targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c4a53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- POST-PROCESSING: GENERATE COMPARISON MATRICES WITH GLOBAL COLORING ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"--- Comparison Matrix Analysis with Global Heatmaps ---\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Convert the list of results into a pandas DataFrame\n",
    "df = pd.DataFrame(results_list)\n",
    "\n",
    "# Extract Components for PIVOTING\n",
    "# Extraction assuming format: {ligand}_variant_{target}_{variant}\n",
    "temp_split = df['Candidate'].str.split('_', expand=True)\n",
    "\n",
    "if temp_split.shape[1] >= 4:\n",
    "    df['Target'] = temp_split[3]\n",
    "    df['Variant'] = temp_split[4]\n",
    "else:\n",
    "    print(\"WARNING: Candidate names do not match the expected format {ligand}_variant_{target}_{variant}. Cannot create comparison matrices.\")\n",
    "    # Stop matrix generation if the format is wrong\n",
    "    exit() \n",
    "\n",
    "# Define Features and Color Maps\n",
    "# Features where HIGHER is BETTER (Green is good)\n",
    "HIGH_IS_BETTER = [\"ipTM\", \"Mean pLDDT\", \"Loop pLDDT\"] \n",
    "# Features where LOWER is BETTER (Red is good, so use reverse colormap)\n",
    "LOW_IS_BETTER = [\"Interface PAE (Loop)\"] \n",
    "\n",
    "features_to_pivot = HIGH_IS_BETTER + LOW_IS_BETTER \n",
    "\n",
    "comparison_matrices = {}\n",
    "\n",
    "for feature in features_to_pivot:\n",
    "    try:\n",
    "        # A. Calculate Global Min/Max for Coloring\n",
    "        # Use the entire column's min/max to ensure global color scaling\n",
    "        global_min = df[feature].min()\n",
    "        global_max = df[feature].max()\n",
    "        \n",
    "        # B. Determine Colormap (Green for good, Red for bad)\n",
    "        if feature in HIGH_IS_BETTER:\n",
    "            cmap = 'RdYlGn'\n",
    "        elif feature in LOW_IS_BETTER:\n",
    "            # Reverse colormap (RdYlGn_r) makes low values green and high values red\n",
    "            cmap = 'RdYlGn_r'\n",
    "        else:\n",
    "            cmap = 'Blues' # Default fallback\n",
    "            \n",
    "        # C. Create the Pivot Table\n",
    "        pivot_table = df.pivot_table(\n",
    "            index='Variant', \n",
    "            columns='Target', \n",
    "            values=feature,\n",
    "            aggfunc='mean'\n",
    "        )\n",
    "        \n",
    "        # D. Apply Global Background Gradient\n",
    "        styled_table = pivot_table.style.background_gradient(\n",
    "            cmap=cmap,\n",
    "            # Pass the global min/max for scaling across all cells in the matrix\n",
    "            vmin=global_min, \n",
    "            vmax=global_max\n",
    "        )\n",
    "        \n",
    "        comparison_matrices[feature] = styled_table\n",
    "        \n",
    "        print(f\"\\n--- Comparison Matrix: {feature} ---\")\n",
    "        display(styled_table)\n",
    "\n",
    "        # Save the styled table\n",
    "        styled_table.to_excel(dir / f\"Comparison_Matrix_{feature.replace(' ', '_')}.xlsx\", engine='openpyxl')\n",
    "        latex_table = styled_table.hide(axis=\"index\").to_latex(caption=f\"AlphaFold {feature} Summary\", label=f\"tab:af_feature_{feature.replace(' ', '_')}_sum\", convert_css=True)\n",
    "        with open(dir / f\"Comparison_Matrix_{feature.replace(' ', '_')}.tex\", 'w') as f:\n",
    "            f.write(latex_table)\n",
    "        \n",
    "    except KeyError:\n",
    "        print(f\"Skipping {feature}: Column not found in DataFrame.\")\n",
    "\n",
    "print(\"\\nMatrix generation complete. Global coloring applied based on the min/max of each feature across all data points.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3338cb10",
   "metadata": {},
   "source": [
    "### Feature discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc18a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize, to_hex\n",
    "\n",
    "# --- Helper Function for Coloring (UPDATED) ---\n",
    "def color_cells(val, cmap, norm):\n",
    "    \"\"\"\n",
    "    Applies a background color to a cell based on its numeric value\n",
    "    and dynamically sets text color for readability.\n",
    "    \"\"\"\n",
    "    # Get the color as an RGBA tuple from the colormap\n",
    "    rgba = cmap(norm(val))\n",
    "    \n",
    "    # Convert RGBA to solid RGB for hex and brightness calculation\n",
    "    # We drop the alpha here as Excel doesn't handle it, and we want opaque hex\n",
    "    r, g, b = (np.array(rgba[:3]) * 255).astype(int)\n",
    "    \n",
    "    # Convert the color to a hex string (e.g., '#AABBCC'), which Excel understands\n",
    "    hex_color = to_hex([r/255, g/255, b/255]) # to_hex expects values between 0 and 1\n",
    "\n",
    "    # Calculate perceived brightness (YIQ formula)\n",
    "    brightness = (r * 299 + g * 587 + b * 114) / 1000\n",
    "    \n",
    "    # Choose text color based on brightness\n",
    "    text_color = '#FFFFFF' if brightness < 128 else '#000000' # White for dark, Black for light\n",
    "\n",
    "    # Return the CSS style for background and text color\n",
    "    return f'background-color: {hex_color}; color: {text_color}'\n",
    "\n",
    "output_dir = Path(\"./analysis_output\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "temp_split = df['Candidate'].str.split('_', expand=True)\n",
    "df['Target'] = temp_split[3]\n",
    "df['Variant'] = temp_split[4]\n",
    "\n",
    "HIGH_IS_BETTER = [\"ipTM\", \"Mean pLDDT\", \"Loop pLDDT\"]\n",
    "LOW_IS_BETTER = [\"Interface PAE (Loop)\"]\n",
    "features_to_analyze = HIGH_IS_BETTER + LOW_IS_BETTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7318a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PRE-PROCESSING: CALCULATE LOCAL Z-SCORES (FOR ALL ANALYSES NOW) ---\n",
    "# This Z-score is calculated *across targets* for each variant.\n",
    "for feature in features_to_analyze:\n",
    "    # Use transform to calculate z-scores within each variant group and align it back to the original df\n",
    "    df[f'{feature}_local_zscore'] = df.groupby('Variant')[feature].transform(\n",
    "        lambda x: (x - x.mean()) / x.std() if x.std() > 0 else 0\n",
    "    )\n",
    "\n",
    "# --- ANALYSIS 1: MOST SIGNIFICANT TARGET (USING LOCAL Z-SCORE) ---\n",
    "# This analysis is now simpler as the local_zscore is pre-calculated.\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"--- Analysis 1: Most Significant Target per Variant (Z-Score Across Targets) ---\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "z_score_summary_text, z_score_summary_numeric = {}, {}\n",
    "for feature in features_to_analyze:\n",
    "    text, numeric = {}, {}\n",
    "    for variant, group in df.groupby('Variant'):\n",
    "        best_idx = group[f'{feature}_local_zscore'].idxmax() if feature in HIGH_IS_BETTER else group[f'{feature}_local_zscore'].idxmin()\n",
    "        best_row = df.loc[best_idx]\n",
    "        z_val = best_row[f'{feature}_local_zscore']\n",
    "        text[variant] = f\"{best_row['Target']} (Z={z_val:.2f})\"\n",
    "        numeric[variant] = z_val\n",
    "    z_score_summary_text[feature] = text\n",
    "    z_score_summary_numeric[feature] = numeric\n",
    "\n",
    "z_score_text_df = pd.DataFrame(z_score_summary_text)\n",
    "z_score_numeric_df = pd.DataFrame(z_score_summary_numeric)\n",
    "# (Styling and saving logic is unchanged)\n",
    "styler_df = pd.DataFrame('', index=z_score_text_df.index, columns=z_score_text_df.columns)\n",
    "g_min, g_max = z_score_numeric_df.min().min(), z_score_numeric_df.max().max()\n",
    "norm = Normalize(vmin=g_min, vmax=g_max)\n",
    "for feature in styler_df.columns:\n",
    "    cmap = plt.get_cmap('RdYlGn' if feature in HIGH_IS_BETTER else 'RdYlGn_r')\n",
    "    styler_df[feature] = z_score_numeric_df[feature].apply(lambda val: color_cells(val, cmap, norm))\n",
    "styled_summary = z_score_text_df.style.apply(lambda x: styler_df, axis=None)\n",
    "display(styled_summary)\n",
    "excel_path = output_dir / \"Significant_Targets_A_Summary_Styled.xlsx\"\n",
    "styled_summary.to_excel(excel_path, engine='openpyxl')\n",
    "print(f\"\\nStyled summary table saved to: {excel_path}\")\n",
    "\n",
    "\n",
    "# --- ANALYSIS 2: VARIANT RANKING BY LOCAL Z-SCORE (UPDATED) ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"--- Analysis 2: Styled Variant Ranking for Each Target (by Local Z-Score/Selectivity) ---\")\n",
    "print(\"=\"*80)\n",
    "for feature in features_to_analyze:\n",
    "    text_data, numeric_data = {}, {}\n",
    "    for target_name, group in df.groupby('Target'):\n",
    "        sort_ascending = feature in LOW_IS_BETTER\n",
    "        # Use the pre-calculated LOCAL z-score for sorting\n",
    "        sorted_group = group.sort_values(by=f'{feature}_local_zscore', ascending=sort_ascending)\n",
    "        text_data[target_name] = [f\"{row['Variant']} (Z={row[f'{feature}_local_zscore']:.2f})\" for _, row in sorted_group.iterrows()]\n",
    "        numeric_data[target_name] = sorted_group[f'{feature}_local_zscore'].tolist()\n",
    "    rank_df_text = pd.DataFrame(text_data); rank_df_numeric = pd.DataFrame(numeric_data)\n",
    "    rank_df_text.index = rank_df_numeric.index = rank_df_text.index + 1\n",
    "    rank_df_text.index.name = \"Rank\"\n",
    "    cmap = plt.get_cmap('RdYlGn' if feature in HIGH_IS_BETTER else 'RdYlGn_r')\n",
    "    norm = Normalize(vmin=rank_df_numeric.min().min(), vmax=rank_df_numeric.max().max())\n",
    "    styled_rank_df = rank_df_text.style.apply(lambda x: rank_df_numeric.map(lambda val: color_cells(val, cmap, norm)), axis=None)\n",
    "    print(f\"\\n--- Local Z-Score Ranks for: {feature} ---\"); display(styled_rank_df)\n",
    "    excel_path = output_dir / f\"Ranking_Local_ZScore_Target_Styled_{feature.replace(' ', '_')}.xlsx\"\n",
    "    styled_rank_df.to_excel(excel_path, engine='openpyxl')\n",
    "    print(f\"Styled Local Z-Score ranking table saved to: {excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492c6014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PRE-PROCESSING: CALCULATE Z-SCORES ---\n",
    "for feature in features_to_analyze:\n",
    "    mean, std = df[feature].mean(), df[feature].std()\n",
    "    df[f'{feature}_zscore'] = 0 if std == 0 else (df[feature] - mean) / std\n",
    "\n",
    "# --- ANALYSIS 1: MOST SIGNIFICANT TARGET SUMMARY ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"--- Analysis 1: Most Statistically Significant Target for Each Variant ---\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create the text and numeric DataFrames as before\n",
    "z_score_summary_text, z_score_summary_numeric = {}, {}\n",
    "for feature in features_to_analyze:\n",
    "    text, numeric = {}, {}\n",
    "    for variant, group in df.groupby('Variant'):\n",
    "        # Find the row with the most desirable Z-score\n",
    "        best_row = group.loc[group[f'{feature}_zscore'].idxmax()] if feature in HIGH_IS_BETTER else group.loc[group[f'{feature}_zscore'].idxmin()]\n",
    "        z_val = best_row[f'{feature}_zscore']\n",
    "        text[variant] = f\"{best_row['Target']} (Z={z_val:.2f})\"\n",
    "        numeric[variant] = z_val\n",
    "    z_score_summary_text[feature] = text\n",
    "    z_score_summary_numeric[feature] = numeric\n",
    "\n",
    "z_score_text_df = pd.DataFrame(z_score_summary_text)\n",
    "z_score_text_df.index.name = \"Variant\"\n",
    "z_score_numeric_df = pd.DataFrame(z_score_summary_numeric)\n",
    "z_score_numeric_df.index.name = \"Variant\"\n",
    "\n",
    "# --- Styling Logic for Analysis 1 ---\n",
    "# Create an empty DataFrame to hold the CSS styles\n",
    "styler_df = pd.DataFrame('', index=z_score_text_df.index, columns=z_score_text_df.columns)\n",
    "\n",
    "# Find the global min and max Z-score for consistent color scaling\n",
    "g_min, g_max = z_score_numeric_df.min().min(), z_score_numeric_df.max().max()\n",
    "norm = Normalize(vmin=g_min, vmax=g_max)\n",
    "\n",
    "# Iterate through each column (feature) to apply the correct colormap\n",
    "for feature in styler_df.columns:\n",
    "    # Choose the colormap based on whether high or low is better\n",
    "    cmap = plt.get_cmap('RdYlGn' if feature in HIGH_IS_BETTER else 'RdYlGn_r')\n",
    "    # Apply the coloring function to each cell in the column\n",
    "    styler_df[feature] = z_score_numeric_df[feature].apply(lambda val: color_cells(val, cmap, norm))\n",
    "\n",
    "# Apply the generated styles to the text DataFrame\n",
    "styled_summary = z_score_text_df.style.apply(lambda x: styler_df, axis=None)\n",
    "\n",
    "print(\"This table shows the most significant target, colored by its Z-score.\")\n",
    "display(styled_summary)\n",
    "\n",
    "# Save the styled table to an Excel file\n",
    "excel_path = output_dir / \"Significant_Targets_Summary_B_Styled.xlsx\"\n",
    "styled_summary.to_excel(excel_path, engine='openpyxl')\n",
    "print(f\"\\nStyled summary table saved to: {excel_path}\")\n",
    "\n",
    "\n",
    "# --- 4. ANALYSIS 2: VARIANT RANKING BY Z-SCORE (STYLED) ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"--- Analysis 2: Styled Variant Ranking for Each Target (by Z-Score) ---\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for feature in features_to_analyze:\n",
    "    text_data, numeric_data = {}, {}\n",
    "    for target_name, group in df.groupby('Target'):\n",
    "        sort_ascending = feature in LOW_IS_BETTER\n",
    "        sorted_group = group.sort_values(by=f'{feature}_zscore', ascending=sort_ascending)\n",
    "        \n",
    "        text_data[target_name] = [f\"{row['Variant']} (Z={row[f'{feature}_zscore']:.2f})\" for _, row in sorted_group.iterrows()]\n",
    "        numeric_data[target_name] = sorted_group[f'{feature}_zscore'].tolist()\n",
    "\n",
    "    rank_df_text = pd.DataFrame(text_data)\n",
    "    rank_df_numeric = pd.DataFrame(numeric_data)\n",
    "\n",
    "    # Make the rank index 1-based for the text table\n",
    "    rank_df_text.index = rank_df_text.index + 1\n",
    "    rank_df_text.index.name = \"Rank\"\n",
    "    \n",
    "    # *** THE FIX: Ensure the numeric DataFrame has the exact same index ***\n",
    "    rank_df_numeric.index = rank_df_text.index\n",
    "\n",
    "    # Set up colormap and normalization for styling\n",
    "    cmap = plt.get_cmap('RdYlGn' if feature in HIGH_IS_BETTER else 'RdYlGn_r')\n",
    "    norm = Normalize(vmin=rank_df_numeric.min().min(), vmax=rank_df_numeric.max().max())\n",
    "    \n",
    "    # Apply styling\n",
    "    styled_rank_df = rank_df_text.style.apply(lambda x: rank_df_numeric.map(lambda val: color_cells(val, cmap, norm)), axis=None)\n",
    "    \n",
    "    print(f\"\\n--- Z-Score Ranks for: {feature} ---\")\n",
    "    display(styled_rank_df)\n",
    "    \n",
    "    excel_path = output_dir / f\"Ranking_ZScore_Styled_{feature.replace(' ', '_')}.xlsx\"\n",
    "    styled_rank_df.to_excel(excel_path, engine='openpyxl')\n",
    "    print(f\"Styled Z-Score ranking table saved to: {excel_path}\")\n",
    "\n",
    "\n",
    "# --- ANALYSIS 3: VARIANT RANKING BY RAW SCORE (STYLED) ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"--- Analysis 3: Styled Variant Ranking for Each Target (by Raw Score) ---\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for feature in features_to_analyze:\n",
    "    text_data, numeric_data = {}, {}\n",
    "    for target_name, group in df.groupby('Target'):\n",
    "        sort_ascending = feature in LOW_IS_BETTER\n",
    "        sorted_group = group.sort_values(by=feature, ascending=sort_ascending)\n",
    "        \n",
    "        text_data[target_name] = [f\"{row['Variant']} (Score={row[feature]:.3f})\" for _, row in sorted_group.iterrows()]\n",
    "        numeric_data[target_name] = sorted_group[feature].tolist()\n",
    "\n",
    "    rank_df_text = pd.DataFrame(text_data)\n",
    "    rank_df_numeric = pd.DataFrame(numeric_data)\n",
    "\n",
    "    # Make the rank index 1-based for the text table\n",
    "    rank_df_text.index = rank_df_text.index + 1\n",
    "    rank_df_text.index.name = \"Rank\"\n",
    "\n",
    "    # *** THE FIX: Ensure the numeric DataFrame has the exact same index ***\n",
    "    rank_df_numeric.index = rank_df_text.index\n",
    "\n",
    "    # Set up colormap and normalization\n",
    "    cmap = plt.get_cmap('RdYlGn' if feature in HIGH_IS_BETTER else 'RdYlGn_r')\n",
    "    norm = Normalize(vmin=rank_df_numeric.min().min(), vmax=rank_df_numeric.max().max())\n",
    "\n",
    "    # Apply styling\n",
    "    styled_rank_df = rank_df_text.style.apply(lambda x: rank_df_numeric.map(lambda val: color_cells(val, cmap, norm)), axis=None)\n",
    "    \n",
    "    print(f\"\\n--- Raw Score Ranks for: {feature} ---\")\n",
    "    display(styled_rank_df)\n",
    "\n",
    "    excel_path = output_dir / f\"Ranking_RawScore_Styled_{feature.replace(' ', '_')}.xlsx\"\n",
    "    styled_rank_df.to_excel(excel_path, engine='openpyxl')\n",
    "    print(f\"Styled Raw Score ranking table saved to: {excel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb391a05",
   "metadata": {},
   "source": [
    "## Save Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccff2d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FINAL SUMMARY ---\n",
    "if results_list:\n",
    "    display(HTML(\"<hr><h1>Final Summary Ranking</h1>\"))\n",
    "    summary_df = pd.DataFrame(results_list)\n",
    "    summary_df_sorted = summary_df.sort_values(by=\"Loop pLDDT\", ascending=False).reset_index(drop=True)\n",
    "    #summary_df_sorted = summary_df_sorted[['Candidate', 'ipTM', 'Mean pLDDT']]\n",
    "    \n",
    "    # Style the dataframe for better readability\n",
    "    styled_summary_df = summary_df_sorted.style.background_gradient(subset=['ipTM'], cmap='viridis').format({'ipTM': '{:.4f}', 'Mean pLDDT': '{:.2f}'})\n",
    "    styled_summary_df = styled_summary_df.background_gradient(subset=['Mean pLDDT'], cmap='viridis')\n",
    "    styled_summary_df = styled_summary_df.background_gradient(subset=['Loop pLDDT'], cmap='viridis')\n",
    "    styled_summary_df = styled_summary_df.background_gradient(subset=['Interface PAE (Loop)'], cmap='viridis_r')\n",
    "    display(styled_summary_df)\n",
    "    \n",
    "    styled_summary_df.to_excel(dir / 'AlphaFold_Summary.xlsx', engine='openpyxl', index=False)\n",
    "    latex_table = styled_summary_df.hide(axis=\"index\").to_latex(caption=f\"AlphaFold Summary\", label=f\"tab:af_multi_sum\", convert_css=True)\n",
    "    latex_table = latex_table.replace(\"fold_\", \"\").replace(\"_\", \" \").replace(\".result\", \"\")\n",
    "    with open(dir / f\"AlphaFold_Summary.tex\", 'w', encoding='utf-8') as f:\n",
    "        f.write(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
